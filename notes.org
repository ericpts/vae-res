* VAE Project

* Purpose
  Test out if it is possible to make VAE's each learn to recognize a different
  object.

  For example, let us consider the MNIST dataset restricted only to the digits 0
  and 1.
  We would like to have 2 VAE's, and have each one of them learn to represent the
  digit 0, and the other one learn to represent the digit 1.


* Project structure
** ~generate.py~ -- once a model has been trained, use this to sample images.
** ~train.py~ -- run this in order to train the model.
** ~vae.py~ -- this is the base variational autoencoder model/
** ~supervae.py~ -- this is the model which contains multiple vae's inside, each of
   which is supposed to learn a different concept.


* Tasks
** DONE Implement Beta-VAE.
   CLOSED: [2019-03-12 Tue 17:49]
** DONE Figure out why running on two datasets causes the error.
   CLOSED: [2019-03-11 Mon 14:35]
`tf.function-decorated function tried to create variables on non-first call.`

** DONE Implement entropy loss.
   CLOSED: [2019-03-15 Fri 18:26]
*** Do a pixel-wise entropy function (i.e., for each pixel consider that the VAE's give a probability distribution, and compute the entropy for each pixel).
*** Then take the sum of all entropies, and add Alpha * log(S) to the loss function, where Alpha is a hyperparameter.
*** Keep in mind that maybe we have to normalize the Entropy term depending on the number of VAE's.
** TODO Implement VAE's for 3 digits.
** DONE Figure out what is the best way to freeze a VAE
   CLOSED: [2019-03-15 Fri 18:25]
*** One way would be to make the learning rate very small, so that nothing changes.



* Solved issues
** The confidences for both models always look like coffee beans.
   Is this ok?
   A: If you decrease the entropy loss coefficient, the confidences start becoming more descriptive.
** VAE_1 learns both 0 and 1.
   This seems to be unavoidable, as encoding the digit iself takes only 1 bit.
*** Maybe an idea would be to make the models so weak, that they are unable to
    learn two digits at the same time.
    A: This does not work, because weak models just split the work of drawing a 0.
** Make VAE_1 learn a residual between the input picture and what VAE_0 predicts.
   This should have the effect that it does not even have the chance to learn what a 0 is.
   A: This is not that useful, because residuals impose a sequence-dependence on the order of learning.

* Current issues
** VAE_1 may collapse.
   Occasionally, VAE_1 will not learn anything. As soon as it starts training, its KL-loss becomes 0 and stays 0.
   This may be because the KL loss for VAE_0 will be fixed and cannot change, and hence maybe not much is left
   over for VAE_1.

   One issue: depending on \Beta, maybe VAE_0 "gobbles up" all of the available information.
   This way, when VAE_1 starts learning, it cannot learn anything because doing so would
   incur a pretty hefty KL-loss penalty.



* Outstanding ideas
** Decrease Gamma and increase the KL-loss while training VAE_1, in order to encourage it to
   learn one single thing, and learn it well.
   However, since VAE_0 is not learning anything anymore, maybe we should also decrease the KL-loss weight.
** After VAE_0 has learned its digit, find out the KL loss. Then try to force VAE_1 to have
   a similar KL loss, by using the Beta-VAE paper trick.
** Add loss for generating images: if you decide to output a non-trivial pixel, then you should
   be very confident in your prediction.
   Another idea in a similar fashion: if you output an image but you have low confidence, don't even bother.
** Divide the KL-loss by the number of active VAE's.
   This way, when we active more of them, the new ones still have leftover capacity.
** Add FC to end of encoder.
   It seems that most models for CNN's have two FC's at the end: one with arbitrary size and one for the latent dimension.
   It might be wise to also augment our model with two FC's instead of a single one.


* Current observations:
** Model almost working!
*** Gamma=0.005
    ~! python3 train.py --name colab --beta 1 --gamma 0.005 --epochs 40 80 --latent_dim 8 --nlayers 3~
    VAE_1 seems to 'barely' learn anything about zeroes, in that it draws much in a much uglier way than the 1's.
    Furthermore, the confidences of VAE_1 for the zeroes are very very low (almost black).
    This might mean two things:
    1) The entropy loss is a little bit too high, and so VAE_1 is forced to learn about zeroes only to insure that
       there is not too much entropy loss incurred.
    2) VAE_1 has to much available entropy, and decided to spend some of it on the wrong digit.
    #+CAPTION: Initial progress
    #+attr_html: :width 700px
    [[file:./_org_res/init_progress.png]]
*** Gamma=0.0002
    When gamma is too small, VAE_0 has very high confidences where there is a 0, as well as where there is nothing.
    In accordance, VAE_1 either predicts 1's where they actually exist, or it puts a very low confidence very generic 0
    everywhere else.
    ~! python3 train.py --name colab --beta 1 --gamma 0.0002 --epochs 40 80 --latent_dim 8 --nlayers 3~
    #+CAPTION: Gamma too small
    #+attr_html: :width 700px
    [[file:./_org_res/big_gamma_init_progress.png]]
