\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/r>>}
\@writefile{toc}{\changetocdepth  {2}}
\babel@aux{english}{}
\HyPL@Entry{2<</S/r>>}
\@writefile{toc}{\contentsline {chapter}{Contents}{iii}{section*.1}\protected@file@percent }
\citation{bib:vae_paper}
\HyPL@Entry{6<</S/D>>}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\citation{bib:monet}
\citation{bib:iodine}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Related work}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Model}{5}{chapter.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}ParallelVAE}{5}{section.3.1}\protected@file@percent }
\citation{bib:betavae}
\citation{bib:monet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A diagram of how the model operates.}}{6}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Training}{7}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Intuition}{7}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Results}{9}{chapter.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}MNIST}{9}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}2-MNIST}{9}{subsection.4.1.1}\protected@file@percent }
\newlabel{fig:2mnist}{{4.1.1}{10}{2-MNIST}{Item.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Results of training on 2-MNIST. Each picture has 6 rows: first row is input image $X$, second row is confidence mask of VAE-0 $\mathaccentV {hat}45E{m}_{0}$, third row is reconstruction of VAE-0 $\mathaccentV {hat}45E{X}_{0}$, fourth row is $\mathaccentV {hat}45E{m}_{1}$, fifth row is $\mathaccentV {hat}45E{X}_{1}$, and last row is weighted reconstruction. }}{10}{figure.4.1}\protected@file@percent }
\newlabel{fig:5mnist}{{4.1.2}{10}{5-MNIST}{subsection.4.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Results of training on 5-MNIST. Each picture has 12 rows: first row is input image $X$, last row is reconstructed image. In between, each adjacent pair of rows represents the confidences $\mathaccentV {hat}45E{m}_k$ and the reconstructions $\mathaccentV {hat}45E{X}_k$ for each of the $K = 5$ VAE's. Note that even though the digit $5$ appears as part of the input, none of the models were trained on it: this is just test data. We include it only to see how models generalize to unseen digits. }}{10}{figure.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}5-MNIST}{10}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Together training}{11}{subsection.4.1.3}\protected@file@percent }
\citation{bib:fashion-mnist}
\newlabel{fig:5mnist-together}{{4.1.3}{12}{Together training}{subsection.4.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Results of together-training on 4-MNIST. We can see that the VAE's indeed learn to not output anything unless the inpit is their specific digit. }}{12}{figure.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces KL losses for different scenes. Digit ``e'' refers to nothing (i.e., empty). }}{12}{table.4.1}\protected@file@percent }
\newlabel{tab:kl-loss}{{4.1}{12}{KL losses for different scenes. Digit ``e'' refers to nothing (i.e., empty)}{table.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}KL loss as information}{12}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Conclusions from MNIST}{12}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Fashion MNIST}{12}{section.4.2}\protected@file@percent }
\citation{bib:clevr}
\citation{fig:clevr-deconv}
\citation{bib:spatial-broadcast-decoder}
\citation{bib:iodide}
\newlabel{fig:fashion-mnist}{{4.2}{13}{Fashion MNIST}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Results of together-training on Fashion-MNIST. We can see that each VAE models one object (the one it is confident about). }}{13}{figure.4.4}\protected@file@percent }
\newlabel{fig:clevr-deconv}{{4.3}{13}{Clevr}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Results of one VAE on Clevr. The first row is full white, because the VAE is responsible for modelling everything. }}{13}{figure.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Clevr}{13}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Spatial Broadcast Decoder}{13}{subsection.4.3.1}\protected@file@percent }
\citation{bib:monet}
\newlabel{fig:clevr-spatial}{{4.3.1}{14}{Spatial Broadcast Decoder}{subsection.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Results of one s.b. decoder VAE on Clevr. }}{14}{figure.4.6}\protected@file@percent }
\newlabel{fig:clevr-spatial-bwhite}{{4.3.1}{14}{Spatial Broadcast Decoder}{figure.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Results of one s.b. decoder VAE on black \& white Clevr. }}{14}{figure.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Tandem VAE's on Clevr}{14}{subsection.4.3.2}\protected@file@percent }
\newlabel{fig:clevr-tandem}{{4.3.2}{15}{Tandem VAE's on Clevr}{lstnumber.-1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Results of two s.b.-decoder VAE's trained in tandem on black \& white Clevr. }}{15}{figure.4.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Conclusions \& Future work}{17}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {appendix}{\chapternumberline {A}Methods}{19}{appendix.A}\protected@file@percent }
\bibstyle{plain}
\bibdata{refs}
\bibcite{bib:betavae}{1}
\bibcite{bib:monet}{2}
\bibcite{bib:iodine}{3}
\bibcite{bib:clevr}{4}
\bibcite{bib:vae_paper}{5}
\bibcite{bib:spatial-broadcast-decoder}{6}
\bibcite{bib:fashion-mnist}{7}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{21}{appendix*.2}\protected@file@percent }
\memsetcounter{lastsheet}{27}
\memsetcounter{lastpage}{21}
