\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\changetocdepth  {2}}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Contents}{iii}{section*.1}\protected@file@percent }
\citation{bib:vae_paper}
\citation{bib:monet}
\citation{bib:iodine}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Method}{3}{chapter.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}SuperVAE}{3}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A diagram of how the model operates.}}{4}{figure.2.1}\protected@file@percent }
\citation{bib:betavae}
\citation{bib:monet}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Results}{7}{chapter.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}MNIST}{7}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}2-MNIST}{7}{subsection.3.1.1}\protected@file@percent }
\newlabel{fig:2mnist}{{3.1.1}{8}{2-MNIST}{Item.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Results of training on 2-MNIST. Each picture has 6 rows: first row is input image $X$, second row is confidence mask of VAE-0 $\mathaccentV {hat}45E{m}_{0}$, third row is reconstruction of VAE-0 $\mathaccentV {hat}45E{X}_{0}$, fourth row is $\mathaccentV {hat}45E{m}_{1}$, fifth row is $\mathaccentV {hat}45E{X}_{1}$, and last row is weighted reconstruction. }}{8}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}5-MNIST}{9}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Together training}{9}{subsection.3.1.3}\protected@file@percent }
\newlabel{fig:5mnist}{{3.1.2}{10}{5-MNIST}{subsection.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Results of training on 5-MNIST. Each picture has 12 rows: first row is input image $X$, last row is reconstructed image. In between, each adjacent pair of rows represents the confidences $\mathaccentV {hat}45E{m}_k$ and the reconstructions $\mathaccentV {hat}45E{X}_k$ for each of the $K = 5$ VAE's. Note that even though the digit $5$ appears as part of the input, none of the models were trained on it: this is just test data. We include it only to see how models generalize to unseen digits. }}{10}{figure.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces KL losses for different scenes. Digit ``e'' refers to nothing (i.e., empty). }}{11}{table.3.1}\protected@file@percent }
\newlabel{tab:kl-loss}{{3.1}{11}{KL losses for different scenes. Digit ``e'' refers to nothing (i.e., empty)}{table.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}KL loss as information}{11}{subsection.3.1.4}\protected@file@percent }
\newlabel{fig:5mnist-together}{{3.1.3}{12}{Together training}{subsection.3.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Results of together-training on 4-MNIST. We can see that the VAE's indeed learn to not output anything unless the inpit is their specific digit. }}{12}{figure.3.3}\protected@file@percent }
\citation{bib:fashion-mnist}
\citation{bib:clevr}
\citation{fig:clevr-deconv}
\citation{bib:spatial-broadcast-decoder}
\citation{bib:iodide}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Conclusions from MNIST}{13}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Fashion MNIST}{13}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Clevr}{13}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Spatial Broadcast Decoder}{13}{subsection.3.3.1}\protected@file@percent }
\newlabel{fig:fashion-mnist}{{3.2}{14}{Fashion MNIST}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Results of together-training on Fashion-MNIST. We can see that each VAE models one object (the one it is confident about). }}{14}{figure.3.4}\protected@file@percent }
\newlabel{fig:clevr-deconv}{{3.3}{15}{Clevr}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Results of one VAE on Clevr. The first row is full white, because the VAE is responsible for modelling everything. }}{15}{figure.3.5}\protected@file@percent }
\citation{bib:monet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Tandem VAE's on Clevr}{16}{subsection.3.3.2}\protected@file@percent }
\newlabel{fig:clevr-spatial}{{3.3.1}{17}{Spatial Broadcast Decoder}{subsection.3.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Results of one s.b. decoder VAE on Clevr. }}{17}{figure.3.6}\protected@file@percent }
\newlabel{fig:clevr-spatial-bwhite}{{3.3.1}{18}{Spatial Broadcast Decoder}{figure.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Results of one s.b. decoder VAE on black \& white Clevr. }}{18}{figure.3.7}\protected@file@percent }
\newlabel{fig:clevr-tandem}{{3.3.2}{19}{Tandem VAE's on Clevr}{lstnumber.-1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Results of two s.b.-decoder VAE's trained in tandem on black \& white Clevr. }}{19}{figure.3.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Conclusions \& Future work}{21}{chapter.4}\protected@file@percent }
\bibstyle{plain}
\bibdata{refs}
\bibcite{bib:betavae}{1}
\bibcite{bib:monet}{2}
\bibcite{bib:iodine}{3}
\bibcite{bib:clevr}{4}
\bibcite{bib:vae_paper}{5}
\bibcite{bib:spatial-broadcast-decoder}{6}
\bibcite{bib:fashion-mnist}{7}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{23}{appendix*.2}\protected@file@percent }
\memsetcounter{lastsheet}{29}
\memsetcounter{lastpage}{23}
